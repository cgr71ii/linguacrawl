Exception in thread Thread-43:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
Exception in thread Thread-40:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self._target(*self._args, **self._kwargs)
  File "/home/agaliano/linguacrawl/lib/python3.8/site-packages/linguacrawl/multi_site_crawler.py", line 115, in _pick_crawler_and_run_one_doc
    crawler.crawl_one_page()
  File "/home/agaliano/linguacrawl/lib/python3.8/site-packages/linguacrawl/site_crawler.py", line 270, in crawl_one_page
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self.interrupt_crawl()
  File "/home/agaliano/linguacrawl/lib/python3.8/site-packages/linguacrawl/site_crawler.py", line 429, in interrupt_crawl
    self._target(*self._args, **self._kwargs)
  File "/home/agaliano/linguacrawl/lib/python3.8/site-packages/linguacrawl/multi_site_crawler.py", line 115, in _pick_crawler_and_run_one_doc
    self.save_status()
  File "/home/agaliano/linguacrawl/lib/python3.8/site-packages/linguacrawl/site_crawler.py", line 422, in save_status
    crawler.crawl_one_page()
  File "/home/agaliano/linguacrawl/lib/python3.8/site-packages/linguacrawl/site_crawler.py", line 270, in crawl_one_page
    pickle.dump(self.get_status_object(), open(self.dumpfile, 'wb'))
OSError: [Errno 36] File name too long: '/home/agaliano/mm_crawl_output/mm%2Fen%2Fnews-media%2Fnews%2Flatest-news%3Fp_p_id%3Dcom_liferay_asset_publisher_web_portlet_AssetPublisherPortlet_INSTANCE_idasset354%26p_p_lifecycle%3D0%26p_p_state%3Dnormal%26p_p_mode%3Dview%26_com_liferay_asset_publisher_web_portlet_AssetPublisherPortlet_INSTANCE_idasset354_cur%3D849%26_com_liferay_asset_publisher_web_portlet_AssetPublisherPortlet_INSTANCE_idasset354_delta%3D10%26p_r_p_resetCur%3Dfalse%26_com_liferay_asset_publisher_web_portlet_AssetPublisherPortlet_INSTANCE_idasset354_assetEntryId%3D13704951..state'
    self.interrupt_crawl()
  File "/home/agaliano/linguacrawl/lib/python3.8/site-packages/linguacrawl/site_crawler.py", line 429, in interrupt_crawl
    self.save_status()
  File "/home/agaliano/linguacrawl/lib/python3.8/site-packages/linguacrawl/site_crawler.py", line 422, in save_status
    pickle.dump(self.get_status_object(), open(self.dumpfile, 'wb'))
OSError: [Errno 36] File name too long: '/home/agaliano/mm_crawl_output/mm%2Fnews-media%2Fnews%3Fp_p_id%3Dcom_liferay_asset_publisher_web_portlet_AssetPublisherPortlet_INSTANCE_xbY59m5iNi6B%26p_p_lifecycle%3D0%26p_p_state%3Dnormal%26p_p_mode%3Dview%26_com_liferay_asset_publisher_web_portlet_AssetPublisherPortlet_INSTANCE_xbY59m5iNi6B_cur%3D0%26p_r_p_resetCur%3Dfalse%26_com_liferay_asset_publisher_web_portlet_AssetPublisherPortlet_INSTANCE_xbY59m5iNi6B_assetEntryId%3D34993974..state'
ERROR:root:HTTPError (code 403)
ERROR:root:HTTPError (code 403) while trying to read robots.txt for subdomain buzzy.com.mm: disallowing to crawl any page
ERROR:root:HTTPError (code 403)
ERROR:root:HTTPError (code 403) while trying to read robots.txt for subdomain digitaltimes.com.mm: disallowing to crawl any page
ERROR:root:HTTPError (code 403)
ERROR:root:HTTPError (code 403) while trying to read robots.txt for subdomain gtimandalay.tvet.edu.mm: disallowing to crawl any page
ERROR:root:HTTPError (code 403)
ERROR:root:HTTPError (code 403) while trying to read robots.txt for subdomain www.drnandamalabhivamsa.com.mm: disallowing to crawl any page
ERROR:root:HTTPError (code 403)
ERROR:root:HTTPError (code 403)
ERROR:root:HTTPError (code 403) while trying to read robots.txt for subdomain kayahstate.hluttaw.mm: disallowing to crawl any page
ERROR:root:HTTPError (code 403) while trying to read robots.txt for subdomain drnandamalabhivamsa.com.mm: disallowing to crawl any page
ERROR:root:HTTPError (code 403)
ERROR:root:HTTPError (code 403) while trying to read robots.txt for subdomain www.mpt.com.mm: disallowing to crawl any page
ERROR:root:HTTPError (code 403)
ERROR:root:HTTPError (code 403) while trying to read robots.txt for subdomain kayinstate.hluttaw.mm: disallowing to crawl any page
ERROR:root:HTTPError (code 403)
ERROR:root:HTTPError (code 403) while trying to read robots.txt for subdomain mediaone.com.mm: disallowing to crawl any page
ERROR:root:HTTPError (code 403)
ERROR:root:HTTPError (code 403) while trying to read robots.txt for subdomain mandalayregion.hluttaw.mm: disallowing to crawl any page
ERROR:root:HTTPError (code 403)
ERROR:root:HTTPError (code 403) while trying to read robots.txt for subdomain www.moi.gov.mm: disallowing to crawl any page
ERROR:root:HTTPError (code 412)
ERROR:root:HTTPError (code 412) while trying to read robots.txt for subdomain www.bagoregion.gov.mm: disallowing to crawl any page
ERROR:root:HTTPError (code 403)
ERROR:root:HTTPError (code 403) while trying to read robots.txt for subdomain m.moi.gov.mm: disallowing to crawl any page
ERROR:root:HTTPError (code 404)
ERROR:root:HTTPError (code 404) while trying to read robots.txt for subdomain www.maas.edu.mm: allowing to crawl any page
ERROR:root:HTTPError (code 412)
ERROR:root:HTTPError (code 412) while trying to read robots.txt for subdomain bagoregion.gov.mm: disallowing to crawl any page
ERROR:root:HTTPError (code 404)
ERROR:root:HTTPError (code 404) while trying to read robots.txt for subdomain www.iwumd.gov.mm: allowing to crawl any page
ERROR:root:HTTPError (code 404)
ERROR:root:HTTPError (code 404) while trying to read robots.txt for subdomain bsi.gov.mm: allowing to crawl any page
ERROR:root:HTTPError (code 404)
ERROR:root:HTTPError (code 404) while trying to read robots.txt for subdomain www.moee.gov.mm: allowing to crawl any page
ERROR:root:HTTPError (code 403)
ERROR:root:HTTPError (code 403) while trying to read robots.txt for subdomain www.motc.gov.mm: disallowing to crawl any page
ERROR:root:HTTPError (code 403)
ERROR:root:HTTPError (code 403) while trying to read robots.txt for subdomain motc.gov.mm: disallowing to crawl any page
ERROR:root:HTTPError (code 403)
ERROR:root:HTTPError (code 403) while trying to read robots.txt for subdomain www.myanmar.mmtimes.com: disallowing to crawl any page
ERROR:root:HTTPError (code 403)
ERROR:root:HTTPError (code 403) while trying to read robots.txt for subdomain www.mmtimes.com: disallowing to crawl any page
ERROR:root:HTTPError (code 403)
ERROR:root:HTTPError (code 403) while trying to read robots.txt for subdomain myanmar.mmtimes.com: disallowing to crawl any page
Traceback (most recent call last):
  File "/home/agaliano/linguacrawl/bin/linguacrawl", line 44, in <module>
    main(sys.argv[1:])
  File "/home/agaliano/linguacrawl/bin/linguacrawl", line 41, in main
    crawler.start_crawling()
  File "/home/agaliano/linguacrawl/lib/python3.8/site-packages/linguacrawl/multi_site_crawler.py", line 98, in start_crawling
    time.sleep(5)
  File "/home/agaliano/linguacrawl/lib/python3.8/site-packages/linguacrawl/multi_site_crawler.py", line 191, in termsighandler
    crawler.interrupt_crawl()
  File "/home/agaliano/linguacrawl/lib/python3.8/site-packages/linguacrawl/site_crawler.py", line 429, in interrupt_crawl
    self.save_status()
  File "/home/agaliano/linguacrawl/lib/python3.8/site-packages/linguacrawl/site_crawler.py", line 422, in save_status
    pickle.dump(self.get_status_object(), open(self.dumpfile, 'wb'))
OSError: [Errno 36] File name too long: '/home/agaliano/mm_crawl_output/mm%2Fen%2Fnews-media%2Fnews%2Flatest-news%3Fp_p_id%3Dcom_liferay_asset_publisher_web_portlet_AssetPublisherPortlet_INSTANCE_idasset354%26p_p_lifecycle%3D0%26p_p_state%3Dnormal%26p_p_mode%3Dview%26_com_liferay_asset_publisher_web_portlet_AssetPublisherPortlet_INSTANCE_idasset354_cur%3D849%26_com_liferay_asset_publisher_web_portlet_AssetPublisherPortlet_INSTANCE_idasset354_delta%3D10%26p_r_p_resetCur%3Dfalse%26_com_liferay_asset_publisher_web_portlet_AssetPublisherPortlet_INSTANCE_idasset354_assetEntryId%3D13704951..state'
